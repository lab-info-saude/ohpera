{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import ml_time_series as mls\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.MIMEMultipart import MIMEMultipart\n",
    "from email.MIMEText import MIMEText\n",
    "from email.mime.image import MIMEImage\n",
    "\n",
    "def send_email(text, img=False ,toaddr='jorgeluizjk@gmail.com'):\n",
    "    fromaddr = 'ohperaml@gmail.com'\n",
    "    passw = 'ohperaml11'\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = fromaddr\n",
    "    msg['To'] = toaddr\n",
    "    msg['Subject'] = \"Jupyter - Processing completed\"\n",
    "\n",
    "    body = 'Processing completed\\n' + text\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "    \n",
    "    if img!=False:\n",
    "        img_data = open(img, 'rb').read()\n",
    "        image = MIMEImage(img_data, name=os.path.basename(img))\n",
    "        msg.attach(image)\n",
    "\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(fromaddr, passw)\n",
    "    text = msg.as_string()\n",
    "    server.sendmail(fromaddr, toaddr, text)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_signal(emg, low_pass=10., sfreq=2000., high_band=20., low_band=450.):\n",
    "    \"\"\"\n",
    "    emg: EMG data\n",
    "    high: high-pass cut off frequency\n",
    "    low: low-pass cut off frequency\n",
    "    sfreq: sampling frequency\n",
    "    \"\"\"\n",
    "    \n",
    "    # normalise cut-off frequencies to sampling frequency\n",
    "    high_band = high_band/(sfreq/2)\n",
    "    low_band = low_band/(sfreq/2)\n",
    "    \n",
    "    # create bandpass filter for EMG\n",
    "    b1, a1 = sp.signal.butter(4, [high_band,low_band], btype='bandpass')\n",
    "    \n",
    "    # process EMG signal: filter EMG\n",
    "    emg_filtered = sp.signal.filtfilt(b1, a1, emg)    \n",
    "    \n",
    "    # process EMG signal: rectify\n",
    "    emg_rectified = abs(emg_filtered)\n",
    "    \n",
    "    # create lowpass filter and apply to rectified signal to get EMG envelope\n",
    "    low_pass = low_pass/sfreq\n",
    "    b2, a2 = sp.signal.butter(4, low_pass, btype='lowpass')\n",
    "    emg_envelope = sp.signal.filtfilt(b2, a2, emg_rectified)\n",
    "    \n",
    "    return emg_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_fremg(FILE_,Xc):    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot(4, 1, 1).xaxis.set_visible(False)\n",
    "    plt.plot(Xc[:, 0], linewidth=0.2)\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    plt.title('Channel 1')\n",
    "    plt.show()\n",
    "    \n",
    "    # pass sharey=ax1 to ensure the two subplots share the same y axis\n",
    "    ax2 = plt.subplot(4, 1, 2, sharey=ax1).xaxis.set_visible(False)\n",
    "    plt.plot(Xc[:, 1], linewidth=0.2)\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    plt.title('Channel 2')\n",
    "    plt.show()\n",
    "    \n",
    "    ax3 = plt.subplot(4, 1, 3, sharey=ax1).xaxis.set_visible(False)\n",
    "    plt.plot(Xc[:, 2], linewidth=0.2)\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    plt.title('Channel 3')\n",
    "    plt.show()\n",
    "    \n",
    "    ax4 = plt.subplot(4, 1, 4, sharey=ax1)\n",
    "    plt.plot(Xc[:, 3], linewidth=0.2)\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    plt.title('Channel 4')\n",
    "    plt.show()\n",
    "    \n",
    "    #fig_name = FILE_+'_filtered'+str(180)+'.png'\n",
    "    fig.set_size_inches(w=10,h=7)\n",
    "    #fig.savefig('./graphs/'+fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_fft(Xc, fs):\n",
    "    X =np.abs(np.fft.fft(Xc[:, 0]))\n",
    "    f =np.linspace(0, fs,Xc[:, 0].shape[0])\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot(4, 1, 1).xaxis.set_visible(False)\n",
    "    plt.plot(f,X, linewidth=0.2)\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    plt.title('FFT')\n",
    "\n",
    "    # pass sharey=ax1 to ensure the two subplots share the same y axis\n",
    "    X =np.abs(np.fft.fft(Xc[:, 1]))\n",
    "    f =np.linspace(0, fs,Xc[:, 1].shape[0])\n",
    "    ax2 = plt.subplot(4, 1, 2, sharey=ax1).xaxis.set_visible(False)\n",
    "    plt.plot(f,X, linewidth=0.2)\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    #plt.title('Channel 2')\n",
    "\n",
    "    X =np.abs(np.fft.fft(Xc[:, 2]))\n",
    "    f =np.linspace(0, fs,Xc[:, 2].shape[0])\n",
    "    ax3 = plt.subplot(4, 1, 3, sharey=ax1).xaxis.set_visible(False)\n",
    "    plt.plot(f,X, linewidth=0.2)\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    #plt.title('Channel 3')\n",
    "    \n",
    "    X =np.abs(np.fft.fft(Xc[:, 3]))\n",
    "    f =np.linspace(0, fs,Xc[:, 3].shape[0])\n",
    "    ax4 = plt.subplot(4, 1, 4, sharey=ax1)\n",
    "    plt.plot(f,X, linewidth=0.2)\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('mV').set_rotation(0)\n",
    "    #plt.title('Channel 4')\n",
    "    \n",
    "    fig.set_size_inches(w=10,h=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - rms(Xc, window_size)\n",
      " 2 - mav(Xc, window_size)\n",
      " 3 - f_var(Xc, window_size)\n",
      " 4 - f_entropy(Xc, window_size)\n",
      " 5 - wl(Xc, window_size)\n",
      " 6 - f_iemg(Xc, window_size)\n",
      " 7 - wamp(a, alpha) - Not implemented\n",
      " 8 - zc(a, alpha) - Not implementeds\n"
     ]
    }
   ],
   "source": [
    "mls.help_ml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proccess_data(FILE_,DATA,NUM_SAMPLES,LABEL):\n",
    "\n",
    "    X = np.genfromtxt('DB_GAIT/'+FILE_+'.txt', delimiter=\",\", usecols=(1,2,3,4))\n",
    "    \n",
    "    #for i in range(X.shape[1]):\n",
    "    #    if i == 0:\n",
    "    #        Xc = filter_signal(X[:, i], low_pass=180)\n",
    "    #        #plot_fremg(FILE_, Xc)\n",
    "    #    else:\n",
    "    #        Xcp = filter_signal(X[:, i], low_pass=180)\n",
    "    #        #plot_fremg(FILE_, Xcp)\n",
    "    #        Xc = np.vstack((Xc,Xcp))\n",
    "    #Xc = np.transpose(Xc)\n",
    "    #plot_fremg(FILE_, Xc)\n",
    "    Xc = np.hstack((mls.rms(X,50),mls.mav(X,50)))\n",
    "    Xc = np.hstack((Xc,mls.f_var(X,50)))\n",
    "    Xc = np.hstack((Xc,mls.f_entropy(X,50)))\n",
    "    Xc = np.hstack((Xc,mls.wl(X,50)))\n",
    "    Xc = np.hstack((Xc,mls.f_iemg(X,50)))\n",
    "    \n",
    "    #Principal component analysis\n",
    "    #pca = PCA(n_components=24)\n",
    "    #pca.fit(Xc)\n",
    "    #Xc = pca.transform(Xc)\n",
    "    #print pca.explained_variance_ratio_\n",
    "    \n",
    "    print '\\nXc shape ', Xc.shape\n",
    "    \n",
    "    #Create temporal serie\n",
    "    #Xc = mls.generate_envelope(Xc, NUM_SAMPLES)\n",
    "    #print 'Xc temporal-serie shape ', Xc.shape\n",
    "    \n",
    "    #Labeling the type of movement\n",
    "    C = (np.ones(len(Xc))*LABEL).reshape((len(Xc),1))\n",
    "    Xc = np.hstack((Xc.reshape(Xc.shape),C.reshape((len(Xc),1))))\n",
    "    print 'Xc labeled shape ', Xc.shape\n",
    "    \n",
    "# Salving in file on the folder <classifier_data>\n",
    "np.save('./preproc_filtered_data/'+FILE_, Xc, allow_pickle=False)\n",
    "    print FILE_+'.npy'\n",
    "    \n",
    "    DATA.append(FILE_+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_1.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_2.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_3.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_w_4.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_5.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_w_6.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_7.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_8.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_9.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_w_10.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_w_11.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_w_12.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_1.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_2.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_3.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_r_4.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_5.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_r_6.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_7.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_8.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_9.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_10.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_11.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_r_12.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_1.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_2.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_3.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_us_4.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_5.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_us_6.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_7.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_8.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_us_9.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_us_10.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_us_11.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_us_12.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_1.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_2.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_3.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_ds_4.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_5.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_ds_6.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_7.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_8.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_9.npy\n",
      "\n",
      "Xc shape  (4951, 24)\n",
      "Xc labeled shape  (4951, 25)\n",
      "data_ds_10.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_ds_11.npy\n",
      "\n",
      "Xc shape  (5951, 24)\n",
      "Xc labeled shape  (5951, 25)\n",
      "data_ds_12.npy\n",
      "['data_w_1.npy', 'data_w_2.npy', 'data_w_3.npy', 'data_w_4.npy', 'data_w_5.npy', 'data_w_6.npy', 'data_w_7.npy', 'data_w_8.npy', 'data_w_9.npy', 'data_w_10.npy', 'data_w_11.npy', 'data_w_12.npy', 'data_r_1.npy', 'data_r_2.npy', 'data_r_3.npy', 'data_r_4.npy', 'data_r_5.npy', 'data_r_6.npy', 'data_r_7.npy', 'data_r_8.npy', 'data_r_9.npy', 'data_r_10.npy', 'data_r_11.npy', 'data_r_12.npy', 'data_us_1.npy', 'data_us_2.npy', 'data_us_3.npy', 'data_us_4.npy', 'data_us_5.npy', 'data_us_6.npy', 'data_us_7.npy', 'data_us_8.npy', 'data_us_9.npy', 'data_us_10.npy', 'data_us_11.npy', 'data_us_12.npy', 'data_ds_1.npy', 'data_ds_2.npy', 'data_ds_3.npy', 'data_ds_4.npy', 'data_ds_5.npy', 'data_ds_6.npy', 'data_ds_7.npy', 'data_ds_8.npy', 'data_ds_9.npy', 'data_ds_10.npy', 'data_ds_11.npy', 'data_ds_12.npy']\n",
      "Total time for enveloping: 3.36 min\n"
     ]
    }
   ],
   "source": [
    "files_w = ['data_w_1', 'data_w_2', 'data_w_3', 'data_w_4', 'data_w_5', 'data_w_6', 'data_w_7', 'data_w_8', 'data_w_9', \n",
    "           'data_w_10', 'data_w_11', 'data_w_12']\n",
    "files_r = ['data_r_1', 'data_r_2', 'data_r_3', 'data_r_4', 'data_r_5', 'data_r_6', 'data_r_7', 'data_r_8', 'data_r_9', \n",
    "           'data_r_10', 'data_r_11', 'data_r_12']\n",
    "files_us = ['data_us_1', 'data_us_2', 'data_us_3', 'data_us_4', 'data_us_5', 'data_us_6', 'data_us_7', 'data_us_8', \n",
    "            'data_us_9', 'data_us_10', 'data_us_11', 'data_us_12']\n",
    "files_ds = ['data_ds_1', 'data_ds_2', 'data_ds_3', 'data_ds_4', 'data_ds_5', 'data_ds_6', 'data_ds_7', 'data_ds_8', \n",
    "            'data_ds_9', 'data_ds_10', 'data_ds_11', 'data_ds_12']\n",
    "\n",
    "NUM_SAMPLES = 500 #Envelope size.\n",
    "\n",
    "DATA = []\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#Passing the data to processing and labeling them.\n",
    "for i in files_w:\n",
    "    proccess_data(i,DATA,NUM_SAMPLES,0)\n",
    "\n",
    "for i in files_r:\n",
    "    proccess_data(i,DATA,NUM_SAMPLES,1)\n",
    "\n",
    "for i in files_us:\n",
    "    proccess_data(i,DATA,NUM_SAMPLES,2)\n",
    "\n",
    "for i in files_ds:\n",
    "    proccess_data(i,DATA,NUM_SAMPLES,3)\n",
    "\n",
    "print DATA\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "ti = stop - start \n",
    "\n",
    "send_email('\\n Total time for enveloping: %.2f min' % (ti/60))\n",
    "print ('Total time for enveloping: %.2f min' % (ti/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "paplay /usr/share/sounds/freedesktop/stereo/complete.oga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['data_w_1.npy', 'data_w_2.npy', 'data_w_3.npy', 'data_w_4.npy', 'data_w_5.npy', 'data_w_6.npy', 'data_w_7.npy', 'data_w_8.npy', 'data_w_9.npy', 'data_w_10.npy', 'data_w_11.npy', 'data_w_12.npy', 'data_r_1.npy', 'data_r_2.npy', 'data_r_3.npy', 'data_r_4.npy', 'data_r_5.npy', 'data_r_6.npy', 'data_r_7.npy', 'data_r_8.npy', 'data_r_9.npy', 'data_r_10.npy', 'data_r_11.npy', 'data_r_12.npy', 'data_us_1.npy', 'data_us_2.npy', 'data_us_3.npy', 'data_us_4.npy', 'data_us_5.npy', 'data_us_6.npy', 'data_us_7.npy', 'data_us_8.npy', 'data_us_9.npy', 'data_us_10.npy', 'data_us_11.npy', 'data_us_12.npy', 'data_ds_1.npy', 'data_ds_2.npy', 'data_ds_3.npy', 'data_ds_4.npy', 'data_ds_5.npy', 'data_ds_6.npy', 'data_ds_7.npy', 'data_ds_8.npy', 'data_ds_9.npy', 'data_ds_10.npy', 'data_ds_11.npy', 'data_ds_12.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = ['data_w_1.npy', 'data_w_2.npy', 'data_w_3.npy', 'data_w_4.npy', 'data_w_5.npy', 'data_w_6.npy', 'data_w_7.npy', \n",
    "        'data_r_1.npy', 'data_r_2.npy', 'data_r_3.npy', 'data_r_4.npy', 'data_r_5.npy', 'data_r_6.npy', 'data_r_7.npy', \n",
    "        'data_us_1.npy', 'data_us_2.npy', 'data_us_3.npy', 'data_us_4.npy', 'data_us_5.npy', 'data_us_6.npy', \n",
    "        'data_us_7.npy', 'data_ds_1.npy', 'data_ds_2.npy', 'data_ds_3.npy', 'data_ds_4.npy', 'data_ds_5.npy', \n",
    "        'data_ds_6.npy', 'data_ds_7.npy']\n",
    "\n",
    "len(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DATA = ['data_w_1.npy', 'data_w_2.npy', 'data_w_3.npy', 'data_w_4.npy', 'data_w_5.npy', 'data_w_6.npy', 'data_w_7.npy', 'data_w_8.npy', 'data_w_9.npy', 'data_w_10.npy', 'data_w_11.npy', 'data_w_12.npy', 'data_r_1.npy', 'data_r_2.npy', 'data_r_3.npy', 'data_r_4.npy', 'data_r_5.npy', 'data_r_6.npy', 'data_r_7.npy', 'data_r_8.npy', 'data_r_9.npy', 'data_r_10.npy', 'data_r_11.npy', 'data_r_12.npy', 'data_us_1.npy', 'data_us_2.npy', 'data_us_3.npy', 'data_us_4.npy', 'data_us_5.npy', 'data_us_6.npy', 'data_us_7.npy', 'data_us_8.npy', 'data_us_9.npy', 'data_us_10.npy', 'data_us_11.npy', 'data_us_12.npy', 'data_ds_1.npy', 'data_ds_2.npy', 'data_ds_3.npy', 'data_ds_4.npy', 'data_ds_5.npy', 'data_ds_6.npy', 'data_ds_7.npy', 'data_ds_8.npy', 'data_ds_9.npy', 'data_ds_10.npy', 'data_ds_11.npy', 'data_ds_12.npy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total para o envelopamento: 0.01 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(146628, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "Xc = np.load(\"preproc_filtered_data/\"+DATA[0])\n",
    "for i in DATA[1:]:\n",
    "    Xc = np.vstack((Xc,np.load(\"preproc_filtered_data/\"+i))) \n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "ti = stop - start \n",
    "print ('Tempo total para o envelopamento: %.2f min' % (ti/60))\n",
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90740126  0.07342512  0.01197623]\n"
     ]
    }
   ],
   "source": [
    "#Principal component analysis\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(Xc)\n",
    "Xc = pca.transform(Xc)\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99280261211929277"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146628, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xc temporal-serie shape  (146129, 1500)\n"
     ]
    }
   ],
   "source": [
    "#Create temporal serie\n",
    "Xc = mls.generate_envelope(Xc, 500)\n",
    "print 'Xc temporal-serie shape ', Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xc saved as row_data.npy\n"
     ]
    }
   ],
   "source": [
    "np.save('./preproc_filtered_data/row_data', Xc, allow_pickle=False)\n",
    "print 'Xc saved as row_data.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Start ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc = np.load(\"preproc_filtered_data/row_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146129, 1500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((146129, 1498), (146129,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Xc[:,0:(Xc.shape[1]-2)]\n",
    "\n",
    "yz = Xc[:,[(Xc.shape[1]-1)]]\n",
    "y = np.array([])\n",
    "for i in range(len(yz)):\n",
    "    y = np.hstack((y,yz[i]))\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "X_train_std = std.transform(X_train)\n",
    "X_test_std = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102290, 1498)\n"
     ]
    }
   ],
   "source": [
    "print X_train_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process:\n",
      "Started at 21:04:04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fd3d6537abc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m rfc = RandomForestClassifier(n_estimators=600, n_jobs=4, max_features='log2', \n\u001b[1;32m      9\u001b[0m                              warm_start=True)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collumbus/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collumbus/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collumbus/anaconda2/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "print 'Training process:'\n",
    "slt = ('Started at %s' % datetime.now().strftime('%H:%M:%S'))\n",
    "print slt\n",
    "sc = timeit.default_timer()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=600, n_jobs=4, max_features='log2', \n",
    "                             warm_start=True)\n",
    "rfc = rfc.fit(X_train_std, y_train)\n",
    "\n",
    "fc = timeit.default_timer()\n",
    "flt = ('Finished at %s' % datetime.now().strftime('%H:%M:%S'))\n",
    "print flt\n",
    "tc = ('Total time %.4s min' % ((fc - sc)/60))\n",
    "print tc\n",
    "#send_email(('\\n Training process: \\n %s \\n %s \\n %s \\n' % (slt, flt, tc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting process:\n",
      "Started at 13:20:34\n",
      "Finished at 13:20:41\n",
      "Total time 0.11 min\n",
      "ClassifyRF accuracy:---------->100.00 %\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "print 'Predicting process:'\n",
    "slt = ('Started at %s' % datetime.now().strftime('%H:%M:%S'))\n",
    "print slt\n",
    "sc = timeit.default_timer()\n",
    "\n",
    "y_pred = rfc.predict(X_test_std)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = ('ClassifyRF accuracy:---------->%.2f %%' % (accuracy_score(y_test, y_pred)*100))\n",
    "\n",
    "fc = timeit.default_timer()\n",
    "flt = ('Finished at %s' % datetime.now().strftime('%H:%M:%S'))\n",
    "print flt\n",
    "tc = ('Total time %.4s min' % ((fc - sc)/60))\n",
    "print tc\n",
    "print acc\n",
    "#send_email(('\\n Predict process: \\n %s \\n %s \\n %s \\n %s' % (slt, flt, tc, acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfc.pkl']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the classifier to file\n",
    "joblib.dump(rfc, 'rfc.pkl') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the classifier from file\n",
    "rfc = joblib.load('rfc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18808, 1999) (18808,)\n"
     ]
    }
   ],
   "source": [
    "DATAV = ['data_w_10.npy', 'data_r_10.npy', 'data_us_10.npy', 'data_ds_10.npy']\n",
    "\n",
    "Xc = np.load(\"preproc_filtered_data/\"+DATAV[0])\n",
    "for i in DATAV[1:]:\n",
    "    Xc = np.vstack((Xc,np.load(\"preproc_filtered_data/\"+i)))\n",
    "    \n",
    "Xvalid = Xc[:,0:(Xc.shape[1]-2)]\n",
    "\n",
    "yz = Xc[:,[(Xc.shape[1]-1)]]\n",
    "yvalid = np.array([])\n",
    "for i in range(len(yz)):\n",
    "    yvalid = np.hstack((yvalid,yz[i]))\n",
    "\n",
    "print Xvalid.shape, yvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation process:\n",
      "Started at 13:20:48\n",
      "Finished at 13:21:01\n",
      "Total time 0.21 min\n",
      "ClassifyRF accuracy:---------->55.15 %\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "print 'Validation process:'\n",
    "slt = ('Started at %s' % datetime.now().strftime('%H:%M:%S'))\n",
    "print slt\n",
    "sc = timeit.default_timer()\n",
    "\n",
    "std.fit(X_train)\n",
    "X_valid_std = std.transform(Xvalid)\n",
    "y_pred = rfc.predict(X_valid_std)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = ('ClassifyRF accuracy:---------->%.2f %%' % (accuracy_score(y_pred, yvalid)*100))\n",
    "\n",
    "fc = timeit.default_timer()\n",
    "flt = ('Finished at %s' % datetime.now().strftime('%H:%M:%S'))\n",
    "print flt\n",
    "tc = ('Total time %.4s min' % ((fc - sc)/60))\n",
    "print tc\n",
    "print acc\n",
    "#send_email(('\\n Validation process: \\n %s \\n %s \\n %s \\n %s' % (slt, flt, tc, acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bfb8836548f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msend_email\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Validation process: \\n %s \\n %s \\n %s \\n %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'slt' is not defined"
     ]
    }
   ],
   "source": [
    "send_email(('\\n Validation process: \\n %s \\n %s \\n %s \\n %s' % (slt, flt, tc, acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClassifyRF 8  accuracy:---------->54.65 %\n",
    "\n",
    "ClassifyRF 9  accuracy:---------->36.51 %\n",
    "\n",
    "ClassifyRF 10 accuracy:---------->60.83 %\n",
    "\n",
    "ClassifyRF 11 accuracy:---------->62.17 %\n",
    "\n",
    "ClassifyRF 12 accuracy:---------->53.31%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ClassifyRF 8  accuracy:---------->36.00 %\n",
    "\n",
    "ClassifyRF 9  accuracy:---------->50.07 %\n",
    "\n",
    "ClassifyRF 10 accuracy:---------->60.37 %\n",
    "\n",
    "ClassifyRF 11 accuracy:---------->59.10 %\n",
    "\n",
    "ClassifyRF 12 accuracy:---------->50.10 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "class_names = np.array(['Walk', 'Run', 'Up Stairs', 'Down Stairs'])\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, ('%.3f' % cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(yvalid, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "fig = plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "fig.set_size_inches(w=7,h=6)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "fig = plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "fig_name = 'cm.png'\n",
    "fig.set_size_inches(w=7,h=6)\n",
    "fig.savefig(fig_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(yvalid, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "TPa = float(cm[0][0])\n",
    "Eab = float(cm[0][1])\n",
    "Eac = float(cm[0][2])\n",
    "#####################\n",
    "Eba = float(cm[1][0])\n",
    "TPb = float(cm[1][1])\n",
    "Ebc = float(cm[1][2])\n",
    "#####################\n",
    "Eca = float(cm[2][0])\n",
    "Ecb = float(cm[2][1])\n",
    "TPc = float(cm[2][2])\n",
    "\n",
    "Pa = TPa/(TPa+Eba+Eca)\n",
    "Pb = TPb/(TPb+Eab+Ecb)\n",
    "Pc = TPc/(TPc+Eac+Ebc)\n",
    "\n",
    "Ra = TPa/(TPa+Eab+Eab)\n",
    "Rb = TPb/(TPb+Eba+Ebc)\n",
    "Rc = TPc/(TPc+Eca+Ecb)\n",
    "\n",
    "TNa = TPb+Ebc+Ecb+TPc\n",
    "TNb = TPa+Eac+Eca+TPc\n",
    "TNc = TPa+Eab+Eba+TPb\n",
    "\n",
    "Sa = TNa/(TNa+Eba+Eca)\n",
    "Sb = TNb/(TNb+Eab+Eac)\n",
    "Sc = TNc/(TNc+Eac+Ebc)\n",
    "\n",
    "Acc = (TPa+TPb+TPc)/(TPa+Eab+Eac+Eba+TPb+Ebc+Eca+Ecb+TPc)\n",
    "\n",
    "print 'PERFORMANCE MEASURES BY CONFUSION MATRIX'\n",
    "acc = ('Accuracy: %.2f %%' % (Acc*100))\n",
    "print acc \n",
    "print ''\n",
    "sa = ('Sensitivity-A: %.2f %%' % (Ra*100))\n",
    "print sa \n",
    "sb = ('Sensitivity-B: %.2f %%' % (Rb*100))\n",
    "print sb\n",
    "sc = ('Sensitivity-C: %.2f %%' % (Rc*100))\n",
    "print sc\n",
    "print ''\n",
    "pa = ('Precision-A: %.2f %%' % (Pa*100))\n",
    "print pa\n",
    "pb = ('Precision-B: %.2f %%' % (Pb*100))\n",
    "print pb\n",
    "pc = ('Precision-C: %.2f %%' % (Pc*100))\n",
    "print pc\n",
    "print ''\n",
    "spa = ('Specificity-A: %.2f %%' % (Sa*100))\n",
    "print spa\n",
    "spb = ('Specificity-B: %.2f %%' % (Sb*100))\n",
    "print spb\n",
    "spc = ('Specificity-C: %.2f %%' % (Sc*100))\n",
    "print spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "send_email(('\\n Validation process: \\n %s \\n %s \\n %s \\n\\n PERFORMANCE MEASURES BY CONFUSION MATRIX \\n %s \\n\\n %s \\n %s \\n %s \\n\\n %s \\n %s \\n %s \\n\\n %s \\n %s \\n %s \\n\\n' % (slt, flt, tc, acc, sa, sb, sc, pa, pb, pc, spa, spb, spc)), 'cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
